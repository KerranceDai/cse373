# CSE 373 - Analysis of Algorithms

## Table of Contents
1. [Introduction](#lecture-1)
    - Big-O notation
    - Integer exponentiation by squaring
    - Euclid's GCD
    - Least Common Ancestor
2. [String Search](#lecture-2)
    - KMP Algorithm
    - Karp-Rabin Algorithm
3. [Suffix Tree](#lecture-3)
4. [Suffix Array](#lecture-4)
    - Suffix array
    - Random Minimum Query (RMQ)
    - LCP array

<a id="lecture-1"></a>

## Lecture 1: Introduction

### Key definitions
- `Algorithm:` a method to compute a desired output from the given input
- `Problem:` described by the set of possible inputs and the desired output.
- `Computational Model:` the set of elementary operations used by the algorithm

### Big-O notation
- Intuition: the big-O notation lets us state the runtime/space of an algorithm, ignoring details that do not matter for large n (constant factors and lower-order terms).
- $\mathcal{O}$ = upper bound
    - Formal proof:
        - Choose $n_0 \in \mathbb{R}$ and $C \in \mathbb{R}$.
        - If for all $n \geq n_0$, $f(n) \leq C * g(n)$, then $f(n) = \mathcal{O}(g(n))$
    - $5n = \mathcal{O}(n)$
    - $5n = \mathcal{O}(n^2)$
- $\Omega$ = lower bound
    - Formal proof:
        - Choose $n_0 \in \mathbb{R}$ and $C \in \mathbb{R}$.
        - If for all $n \geq n_0$, $f(n) \geq C * g(n)$, then $f(n) = \Omega(g(n))$
    - $5n^2 = \Omega(n)$
    - $n! = \Omega(n)$
- $\Theta$ = tight bound
    - Formal proof:
        - Both conditions for $\mathcal{O}(g(n))$ and $\Omega(g(n))$ hold.
    - $5n = \Theta(n)$
    - $5n^2 = \Theta(n^2)$

### Integer exponentiation by squaring
- Input
    - integers $a, m > 0$ and n $\geq 0$
- Output
    - the value $a^n \mod m$
```py
def FastPow(a, n, m):
    if n == 0:
        return 1 % m
    if n is odd:
        t = FastPow(a, (n - 1)/2, m)
        return (t * t * a) % m
    else:
        t = FastPow(a, n/2, m)
        return (t * t) % m
```

### Bubble sort
- time complexity: $O(n^2)$

### Binary Search
```py
def BinarySearch(A, x):
    low = 1
    high = A.length - 1
    while low + 1 < high:
        mid = floor((low + high) / 2)
        if A[mid] > x:
            high = mid
        else:
            low = mid
    if A[low] = x:
        return True
    else:
        return False
```
- time complexity: $O(\log n)$
    - In each step, we split the range into half.
    - Correctness is usually the bigger problem, edge cases:
        - A.length = 0 or 1
        - search range A[low... high - 1] satisfies high - low <= 3

### Greatest Common Divisor
```py
def euclid(a, b):
    if b == 0:
        return a
    else:
        return euclid(b, a % b)
```
- time complexity: $\mathcal{O}(\log(a+b))$


### Least Common Ancestor
- Part 1
    - Traverse tree and store the entry $a$ and exit $b$ for each node.
    - $u$ is an ancestor of $v$ only if $a(u) \leq a(v) \leq b(v) \leq b(u)$.
    - $\mathcal{O}(n)$ time preprocessing
    - $\mathcal{O}(1)$ time query
- Jumping $k$ nodes up in the tree
    - $jump[v][i]$ contains the node at distance $2^i$ from node $v$ to root.
    - $\mathcal{O}(n \log n)$ space for all $v$
    - Precomputed in $\mathcal{O}(n \log n)$ time:
        - $jump[v][0] = parent(v)$
        - $jump[v][i] = jump[jump[v][i-1]][i-1]$


<a id="lecture-2"></a>

## Lecture 2: String Search

### π array
- integer array, same length as pattern $P$
- each $\pi[j]$ = length of the longest proper border of the substring $P[1..j]$.
```
pattern = ABAABAAAAB

   j    1   2   3   4   5   6   7   8   9   10
P[j]    A   B   A   A   B   A   A   A   A   B
π[j]    0   0   1   1   2   3   4   1   1   2
```
- Can be constructed in $\mathcal{O}(m)$ time, where $m$ is length of $P$.
```py
# arrays are 1-indexed

def ConstructPi(P):
    pi = int[len(P)] {0}        # init all values to 0

    pi[1] = 0                   # first element is always 0
    b = 0                       # counter for border length

    for i in range(2, len(P)):  # iterate until end
        while b > 0 and P[b+1] != P[i]:
            b = pi[b]
        if P[b+1] == P[i]:
            b += 1
        pi[i] = b
```

### KMP Algorithm
- $\mathcal{O}(n+m)$ time
    - $\mathcal{O}(m)$ to construct $\pi$ table
    - $\mathcal{O}(n)$ to run KMP algorithm against string $T$.
- $\mathcal{O}(m)$ extra space
```py
# arrays are 1-indexed

def KMP(str T, str P, int[] pi):

    i = 1       # index in T
    m = 0       # number of characters matched

    while i <= len(T) - len(P) + 1:
        while m < len(P) and T[i+m] == P[m+1]:
            m += 1

        if m == len(P):             # match found
            return i

        if m > 0:                   # partial match
            i = i + (m - pi[m])
            m = pi[m]
        else:                       # no partial match, move index forward
            i += 1
```


### Karp-Rabin Fingerprints
- Choose a prime number $q$.
- Choose a number $r \in [2..q)$ at random.
- $T$ is a string of numbers.
- The Karp-Rabin fingerprint of a substring starting at index $i$ with length $l$ is:
    - $\Phi(i, i+l) = (\sum_{k=1}^{l} T[i+k] * r^{l-k}) \mod q$
```
T = 0102121

i       1   2   3   4   5   6   7
T[i]    0   1   0   2   1   2   1
                i           j

Suppose i = 3 and length = 3
Substring: 212

Suppose q = 13
Suppose r = 10

Phi(i, i+3) = (2 * 10^2) + (2 * 10^1) + (2 * 10^0) = 212 mod 13 = 4
```
- Two identical substrings have the same KR fingerprint.
- Most times, two different substrings have different KR fingerprints.
    - False positive is possible if different substrings have the same KR fingerprint.
- For any $i \leq j \leq k$, if we have any two fingerprints in $\{\Phi(i,j), \Phi(j,k), \Phi(i,k)\}$, then we can compute the third:
    - $\Phi(i,k) = \Phi(i,j) * r^{k-j} + \Phi(j,k) \mod q$
    - $\Phi(i,j) = (\Phi(i,k) - \Phi(j,k)) / r^{k-j}  \mod q$
    - $\Phi(j,k) = \Phi(i,k) - \Phi(i,j) * r^{k-j}  \mod q$
    - Each can be evaluated in $\mathcal{O}(\log n)$ time using exponentiation by squaring.

```
T = 778548784372
   i      j    k

L = Phi(i, j) = 7785487
R = Phi(j, k) = 84372
C = Phi(i, k) = 778548784372

Given L and R, compute C:
C = L * 10^5 + R

Given L and C, compute R:
R = C - L * 10^5
```

### Karp-Rabin String Matching
- With checks, runs in $\mathcal{O}(nm)$ time
- Without checks, runs in $\mathcal{O}(n+m)$ time
- Could result in false positives.
- A sufficiently large $q$ can make the probability of collision smaller.
```py
def KR_Search(int[n] T, int[m] P):
    '''Precompute r^k mod q for all k in[0, m]'''
    h = phi_P(0, m)                 # O(m) time
    for i in range(0, n - m):
        h2 = phi_T(i, i + m)        # O(1) time
        if h == h2:
            '''optional checking'''
            return i + 1
```

<a id="lecture-3"></a>
## Lecture 3: Suffix Tree


<a id="lecture-4"></a>
## Lecture 4: Suffix Array

### Suffix Array
- An array containing all suffixes of a string $T$, sorted in alphabetical (lexigraphical) order.
- Each index contains the position at which the substring begins, which inherently corresponds to that substring. The suffix array only contains numbers.
```
T = banana

i       SA[i]       T[SA[i]..n]
1       7           $
2       6           a$
3       4           ana$
4       2           anana$
5       1           banana$
6       5           na$
7       3           nana$
```
- If the suffix tree is drawn such that each branch is in lexigraphical order from left to right, a traversal of the tree will give the suffix array.
- Suffix array is not as powerful as suffix tree, only contains a subset of information.
- Anything you can do with a suffix tree, you can do with a suffix array with less space but also less efficiency.

### Suffix Array Complexity
- $\mathcal{O}(n)$ space.
- $Occ(T, P)$
    - binary search in suffix array, $\mathcal{O}(\log n)$
    - string comparison with prefix, $\mathcal{O}(m)$
    - time: $\mathcal{O}(m \log n)$
- $|Occ(T, P)|$
    - binary search for lowest index containing prefix; $b$ = index - 1
    - binary search for highest index $e$ containing prefix
    - return $e - b$
    - time: $\mathcal{O}(m \log n)$
- Enumerate all $i \in Occ(T, P)$
    - find $b$ and $e$ as before
    - iterate through all $i \in (b..e]$
    - time: $\mathcal{O}(m \log n + occ)$
- $\min Occ(T,P)$
    - assume a precomputed RMQ for $SA[1..n]$.
    - find $b$ and $e$.
    - find $j = RMQ(b, e)$
    - return $SA[j]$
    - total query time: $\mathcal{O}(m \log n + t_{RMQ})$

### Range Minimum Query (RMQ)
- ( Treated as a blackbox in lecture )
- Input: array $A[1..m]$ of integers
- $RMQ(b, e)$ returns index $k$ such that $A[k]$ is the minimum value in range $A(b..e]$.
- An RMQ data structure can be constructed.
    - $\mathcal{O}(m)$ time to construct
    - $\mathcal{O}(1)$ query possible
    - $\mathcal{O}(m)$ space

### LCP Array
- $LCP(X, Y)$ = length of longest common prefix of $X$ and $Y$.
- $LCP[1] = 0$
- $LCP[i]$ = LCP of string at $SA[i]$ and $SA[i-1]$
```
T = banana

i       SA[i]       LCP[i]      T[SA[i]..n]
1       7           0           $
2       6           0           a$
3       4           1           ana$
4       2           3           anana$
5       1           0           banana$
6       5           0           na$
7       3           2           nana$
```

### Number of Distinct Substrings
- $|Substr(T)| = \frac{n(n+1)}{2}$ − all values in LCP array, where $n$ = number of characters in $T$
```
T = banana

b       a       n       a'      n'      a'      // remove {a, n, a}
ba      an      na      an'     na'             // remove {an, na}
ban     ana     nan     ana'                    // remove {ana}
bana    anan    nana
banan   anana
banana

n(n+1)/2
= 6(7)/2
= 21

21 - 3 - 2 - 1
= 15 distinct substrings
```